{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "8bbedf6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "from random import randrange\n",
    "import time\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#nltk.download('all')\n",
    "import wordnet\n",
    "nlp = spacy.load('en_core_web_lg',  disable=[\"parser\", \"ner\"])\n",
    "import io\n",
    "import random\n",
    "import string \n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer()\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk import pos_tag\n",
    "wnl = WordNetLemmatizer()\n",
    "warnings.filterwarnings('ignore')\n",
    "from pywsd.utils import lemmatize_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf83bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api-football-beta.p.rapidapi.com/players/topscorers\"\n",
    "\n",
    "querystring = {\"season\":\"2022\",\"league\":\"39\"}\n",
    "\n",
    "headers = {\n",
    "    \"X-RapidAPI-Key\": \"62a02ca5ccmsha68a5acf6c698d9p1ffc12jsnbe2b9a765139\",\n",
    "    \"X-RapidAPI-Host\": \"api-football-beta.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "\n",
    "#print (type(response.json()))\n",
    "#print(response.json())\n",
    "df = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "da3ad805",
   "metadata": {},
   "outputs": [],
   "source": [
    "playerid = 0\n",
    "goals = df['response'][playerid]['statistics'][0]['goals']['total']\n",
    "shot = df['response'][playerid]['statistics'][0]['shots']['total']\n",
    "passing = df['response'][playerid]['statistics'][0]['passes']['total']\n",
    "playercode = {'Earling Haaland':0, ' Harry Kane':1, 'Aleksandar Mitrovic':2, 'Ivan Toney':3, 'Leandro Trossard':4, ' M. Miguel Almiron':5, 'Phil Foden':6, 'Roberto Firmino':7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "0b66aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def askplayer(name):\n",
    "    askq = input(\"If you want I can tell you about some of the top scorers in the premiere league. So what do you say, Yes or No? \")\n",
    "    if askq =='yes' or askq == 'Yes':\n",
    "        print(\"Here are the names of some of the top scorers I know, Choose any of those names and I'll tell you all about them\")\n",
    "        print(\"Earling Haaland, Harry Kane, Aleksandar Mitrovic, Ivan Toney, Leandro Trossard, M. Miguel Almiron, Phil Foden, Roberto Firmino\")  \n",
    "       #playerchoose = input(\"So what's your choice \")\n",
    "        while True:\n",
    "            playerchoose = input(\"So what's your choice \")\n",
    "            if playerchoose in playercode.keys():\n",
    "                playerid = (playercode[playerchoose])\n",
    "                #print(playerid)\n",
    "                print(\"hmm...\")\n",
    "                time.sleep(1)\n",
    "                print(\"Ah yes... \" + playerchoose + \" I know all about him. Did you know in this season he has scored a total of \" \n",
    "                      + str(goals) + \" goals and he's attempted a grande total of \" + str(shot) +\" shots\")\n",
    "                #return False\n",
    "                break\n",
    "            else:\n",
    "                print(\"That's not one of the names I gave you... Try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5093c29",
   "metadata": {},
   "outputs": [],
   "source": [
    " def word_tokenization(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    text_tokenized = word_tokenize(text)\n",
    "    \n",
    "    for word in text_tokenized:\n",
    "        if word in stopwords.words('english'):\n",
    "            text_tokenized.remove(word)\n",
    "        \n",
    "    return(text_tokenized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0781d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def taggandlem(text):\n",
    "    global lemmatized_list \n",
    "    global lmt_string\n",
    "    entity_list = []\n",
    "    for word in text:\n",
    "        if 'NN' in word[1]:\n",
    "            entity_list.append(word[0])\n",
    "    \n",
    "    lemmatized_list = []\n",
    "    for lit in entity_list:\n",
    "        lmtz = wnl.lemmatize(lit)\n",
    "        lemmatized_list.append(lmtz)\n",
    "        lmt_string = ' '.join(lemmatized_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "144fa75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lem_response_joined(text):\n",
    "    global lemlist\n",
    "    number = 0\n",
    "    lemlist = []\n",
    "    n=0\n",
    "    for word in   text:\n",
    "        number = number+1\n",
    "     \n",
    "    while n<number:\n",
    "        gg =' '.join(text[n])\n",
    "        lemlist.append(gg)\n",
    "        n=n+1\n",
    "    \n",
    "    #print(lemlist)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ea43d66",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tokenized_respone = word_tokenization(resp1)\n",
    "tagged_response = pos_tag(tokenized_respone)\n",
    "# not working lemaitized_response = lemmatization(resp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10fb29f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens = nltk.sent_tokenize(resp1)\n",
    "word_tokens = nltk.word_tokenize(resp1)\n",
    "lmt_string = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "d7367ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['question'] = ['hello',\n",
    "                    'what is your favourite team',\n",
    "                    'what is your least favourite or most hated team',\n",
    "                    'how long have you been watching football'\n",
    "                    \n",
    "                   ]\n",
    "data['answer'] = ['Hey, my name is Garry I will be answering your football questions, feel free to ask anything',\n",
    "                  'My favourite team is Manchester United',\n",
    "                  'I really hate Manchester City',\n",
    "                 \"I've been watching football since I was two, for as long as I remember I've loved football\",\n",
    "                  \n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "28d61793",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = ['hello',\n",
    "                    'what is your favourite team',\n",
    "                    'what is your least favourite or most hated team',\n",
    "                    'how long have you been watching football'\n",
    "                    \n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "a2b8f4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ['Hey, my name is Garry I will be answering your football questions, feel free to ask anything',\n",
    "                  'My favourite team is Manchester United',\n",
    "                  'I really hate Manchester City',\n",
    "                 \"I've been watching football since I was two, for as long as I remember I've loved football\",    \n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "1d1730e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = []\n",
    "for word in question:\n",
    "    question_list.append(lemmatize_sentence(word,))\n",
    "    \n",
    "lem_response_joined(question_list)\n",
    "question_lem_list = lemlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "786f3da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_list = []\n",
    "for word in response:\n",
    "    response_list.append(lemmatize_sentence(word,))\n",
    "    \n",
    "lem_response_joined(response_list)\n",
    "response_lem_list = lemlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "cc9a2f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello',\n",
       " 'what be your favourite team',\n",
       " 'what be your least favourite or most hated team',\n",
       " 'how long have you be watch football']"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_lem_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "22511f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey , my name be garry i will be answer your football question , feel free to ask anything',\n",
       " 'my favourite team be manchester united',\n",
       " 'i really hate manchester city',\n",
       " \"i 've be watch football since i be two , for as long a i remember i 've love football\"]"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_lem_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "0b135c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "elist = []\n",
    "for word in answer:\n",
    "    elist.append(lemmatize_sentence(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "c6df0297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hey',\n",
       "  ',',\n",
       "  'my',\n",
       "  'name',\n",
       "  'be',\n",
       "  'garry',\n",
       "  'i',\n",
       "  'will',\n",
       "  'be',\n",
       "  'answer',\n",
       "  'your',\n",
       "  'football',\n",
       "  'question',\n",
       "  ',',\n",
       "  'feel',\n",
       "  'free',\n",
       "  'to',\n",
       "  'ask',\n",
       "  'anything'],\n",
       " ['my', 'favourite', 'team', 'be', 'manchester', 'united'],\n",
       " ['i', 'really', 'hate', 'manchester', 'city'],\n",
       " ['i',\n",
       "  \"'ve\",\n",
       "  'be',\n",
       "  'watch',\n",
       "  'football',\n",
       "  'since',\n",
       "  'i',\n",
       "  'be',\n",
       "  'two',\n",
       "  ',',\n",
       "  'for',\n",
       "  'as',\n",
       "  'long',\n",
       "  'a',\n",
       "  'i',\n",
       "  'remember',\n",
       "  'i',\n",
       "  \"'ve\",\n",
       "  'love',\n",
       "  'football']]"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "a44df937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "6abb97d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'what be your favourite team', 'what be your least favourite or most hated team', 'how long have you be watch football']\n"
     ]
    }
   ],
   "source": [
    "lem_response_joined(elist)\n",
    "questions = lemlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "ba8f8a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello',\n",
       " 'what be your favourite team',\n",
       " 'what be your least favourite or most hated team',\n",
       " 'how long have you be watch football']"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc6de46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "ce5f4b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_selection(ui):\n",
    "    sentence_input = [(ui)]\n",
    "    similarity_index_list = cosine_similarity(v.fit_transform(data[\"question\"]), v.transform(sentence_input)).flatten()\n",
    "    output = data.loc[similarity_index_list.argmax(), \"answer\"]\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "46f8228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech(text):\n",
    "    tag = True\n",
    "    #exit_command = ['bye','exit,','goodbye']\n",
    "    while tag == True:\n",
    "        user_input = input()\n",
    "        user_input = user_input.lower()\n",
    "        if user_input == \"bye\" or  user_input == \"exit\" or  user_input == \"goodbye\":\n",
    "            print(\"goodbye\")\n",
    "            tag = False\n",
    "        \n",
    "        elif \"top scorer\" in user_input:\n",
    "            askplayer(\"name\")\n",
    "            \n",
    "        else:\n",
    "            response_selection(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "c2dfde94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top scorer\n",
      "If you want I can tell you about some of the top scorers in the premiere league. So what do you say, Yes or No? yes\n",
      "Here are the names of some of the top scorers I know, Choose any of those names and I'll tell you all about them\n",
      "Earling Haaland, Harry Kane, Aleksandar Mitrovic, Ivan Toney, Leandro Trossard, M. Miguel Almiron, Phil Foden, Roberto Firmino\n",
      "So what's your choice Roberto Firmino\n",
      "hmm...\n",
      "Ah yes... Roberto Firmino I know all about him. Did you know in this season he has scored a total of 18 goals and he's attempted a grande total of 43 shots\n",
      "favourite\n",
      "My favourite team is Manchester United\n",
      "bye\n",
      "goodbye\n"
     ]
    }
   ],
   "source": [
    "speech(\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb02e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549e8ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3e9992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad546a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2653035f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa0c984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e928cc92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9250fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c33507d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4db715",
   "metadata": {},
   "outputs": [],
   "source": [
    "#redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "4e72ffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = TfidfVectorizer()\n",
    "sentence_input = [\"hello\"]\n",
    "similarity_index_list = cosine_similarity(v.fit_transform(data[\"question\"]), v.transform(sentence_input)).flatten()\n",
    "output = data.loc[similarity_index_list.argmax(), \"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4aed6c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_terms(user_input,responses_option):\n",
    "    global freqhash\n",
    "    frequency = 0\n",
    "    freqhash = []\n",
    "    n=0\n",
    "    user_input = user_input.split()\n",
    "    for word in user_input:\n",
    "        if word in responses_option:\n",
    "            frequency +=1\n",
    "            n=n+1\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    print(frequency)\n",
    "    freqhash.append(frequency)\n",
    "\n",
    "def frequency_of_terms(user_input,responses_option,n):\n",
    "    global freqhash\n",
    "    frequency = 0\n",
    "    freqhash = []\n",
    "    \n",
    " #   user_input = user_input.split()\n",
    "    for word in user_input:\n",
    "        if word in responses_option:\n",
    "            frequency +=1\n",
    "            \n",
    "   # if n<3\n",
    "    frequency_of_terms(user_input,responses_option,(1))\n",
    "            \n",
    "            \n",
    "    print(frequency)\n",
    "    freqhash.append(frequency)\n",
    "    \n",
    "    \n",
    "    \n",
    "def frequency_of_terms(user_input,response_option):\n",
    "    global freqhash\n",
    "    frequency = 0\n",
    "    freqhash = []\n",
    "    n=0\n",
    "    user_input = user_input.split()\n",
    "    for word in user_input:\n",
    "        for item in response_option:\n",
    "            if response_option[n] <response_option[3]:\n",
    "                frequency +=1\n",
    "                if response_option[n] <= response_option[-1]:\n",
    "                    n=n+1\n",
    "    print(frequency)\n",
    "    freqhash.append(frequency)\n",
    "    \n",
    "def frequency_of_terms(user_input,responses_option):\n",
    "    global freqhash\n",
    "    frequency = 0\n",
    "    freqhash = []\n",
    "    n=0\n",
    "    user_input = user_input.split()\n",
    "    for word in user_input:\n",
    "        for item in responses_option:\n",
    "            if word in item[n]:\n",
    "                frequency +=1\n",
    "                n=n+1\n",
    "    \n",
    "   # while n<3:\n",
    "    #    frequency_of_terms(user_input,responses_option)\n",
    "        \n",
    "    print(frequency)\n",
    "    freqhash.append(frequency)\n",
    "\n",
    "def frequency_of_terms(user_input,responses_option):\n",
    "    frequency = 0\n",
    "    user_input = user_input.split()\n",
    "    for word in user_input:\n",
    "        for item in responses_option[n] :\n",
    "            if word in item:\n",
    "                if responses_option[:]\n",
    "    print(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4a2565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    #lemmatized_words = [token.lemma_ for token in nlp(text)]\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    lemmatized_words = [token.lemma_ for token in nlp(text)]\n",
    "\n",
    "    for word in lemmatized_words:\n",
    "        if word in stopwords.words('english'):\n",
    "            lemmatized_words.remove(word)\n",
    "    \n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685ddddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unfinished\n",
    "def textresponse(user_response):\n",
    "    robo_response=''\n",
    "    sent_tokens.append(user_response)\n",
    "    tokenized_respone = word_tokenization(user_response)\n",
    "    tagged_response = pos_tag(tokenized_respone)\n",
    "    taggandlem(tagged_response)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea232a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def taggandlem(text):\n",
    "    entity_list = []\n",
    "    for word in text:\n",
    "        if 'NN' in word[1]:\n",
    "            entity_list.append(word[0])\n",
    "\n",
    "    for lit in entity_list:\n",
    "        print(wnl.lemmatize(lit))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321cd6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens = nltk.sent_tokenize(resp1)\n",
    "word_tokens = nltk.word_tokenize(resp1)\n",
    "lmt_string = []\n",
    "\n",
    "\n",
    "def textresponse(user_response):\n",
    "    robo_response=''=\n",
    "    tokenized_response = word_tokenization(user_response)\n",
    "    tagged_response = pos_tag(tokenized_response)\n",
    "    taggandlem(tagged_response)\n",
    "    sent_tokens.append(lmt_string)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    mis_undlist = [\"I am sorry! I don't understand you\",\"I didn't quite get that\",\"I'm sorry can you repeat that\",\"I misunderstood that\",\"I'm sorry what\"]\n",
    "    if(req_tfidf==0):\n",
    "        robo_response=robo_response+mis_undlist[randrange(4)]\n",
    "        return robo_response\n",
    "    else:\n",
    "        robo_response = robo_response+sent_tokens[idx]\n",
    "        return robo_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb274b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech(text):\n",
    "    userinput = input(\"Hello my name is Garry, I will be introducing you to the world of football \")\n",
    "    exit_command = ['bye','exit,','goodbye']\n",
    "    listintro = [\"Do you have anything else that you want to talk about? \",\"What else do you want to ask?\",\"Is there anything else?\",\"What else\"]\n",
    "    \n",
    "    for word in exit_command:\n",
    "        if word in userinput:\n",
    "            return(\"You have chosen to end the chat\")\n",
    "    \n",
    "    \n",
    "    if \"top scorer\" in userinput:\n",
    "        askplayer(\"example\")\n",
    "        \n",
    "    \n",
    "    userinput2 = input(listintro[randrange(4)])\n",
    "    \n",
    "    \n",
    "def speech(text):\n",
    "    userinput = input(\"Hello my name is Garry, I will be introducing you to the world of football \")\n",
    "    exit_command = ['bye','exit,','goodbye']\n",
    "    listintro = [\"Do you have anything else that you want to talk about? \",\"What else do you want to ask?\",\"Is there anything else?\",\"What else\"]\n",
    "    sent_tokens = nltk.sent_tokenize(resp1)\n",
    "    word_tokens = nltk.word_tokenize(resp1)\n",
    "    lmt_string = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for word in exit_command:\n",
    "        if word in userinput:\n",
    "            return(\"You have chosen to end the chat\")\n",
    "            exit()\n",
    "    \n",
    "    \n",
    "    if \"top scorer\" in userinput:\n",
    "        askplayer(\"example\")\n",
    "        \n",
    "    \n",
    "    userinput2 = input(listintro[randrange(4)])\n",
    "    \n",
    "def speech(text):\n",
    "        tag = True\n",
    "        exit_command = ['bye','exit,','goodbye']\n",
    "\n",
    "        user_input = input(\"type in something\")\n",
    "        for word in user_input.lower().split():\n",
    "            if word not in exit_command:\n",
    "                #print(\"yaaaa\")\n",
    "                sentence_input = [user_input]\n",
    "                similarity_index_list = cosine_similarity(v.fit_transform(data[\"question\"]), v.transform(sentence_input)).flatten()\n",
    "                output = data.loc[similarity_index_list.argmax(), \"answer\"]\n",
    "                print(output)\n",
    "\n",
    "        \n",
    "            else:\n",
    "                print(\"goodbye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07d29d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens = nltk.sent_tokenize(resp1)\n",
    "word_tokens = nltk.word_tokenize(resp1)\n",
    "lmt_string = []\n",
    "lmt_corp =  nltk.sent_tokenize(lemmatization(resp1))\n",
    "#may have to reset sent_token every time\n",
    "\n",
    "def textresponse(user_response):\n",
    "    robo_response=''\n",
    "    tokenized_response = word_tokenization(user_response)\n",
    "    tagged_response = pos_tag(tokenized_response)\n",
    "    taggandlem(tagged_response)\n",
    "    sent_tokens.append(lmt_string)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104c6d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_a = \"I've been watching football since I was two\"\n",
    "response_b = \"I hate Manchester City\"\n",
    "response_c = \"hello I like wednesdays. John anything today\"\n",
    "response_d = \"my favorite team is Manchester United\"\n",
    "response_e = \"I've been watching football since I was two\"\n",
    "blank_spot = \"player\"\n",
    "\n",
    "\n",
    "responses = [response_a, response_b, response_c, response_d, response_e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2940683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k1=open('responses.txt','r',errors = 'ignore')\n",
    "resp1 =k1.read()\n",
    "resp1 = resp1.lower()# converts to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbd6b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exit_chat(tile):\n",
    "    exit_command = ['bye','exit,','goodbye']\n",
    "    for word in exit_command:\n",
    "        if word in tile:\n",
    "            return(\"You have chosen to end the chat\")\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6507302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lem(text):\n",
    "    global lemmatized_list \n",
    "    global lmt_string\n",
    "    entity_list = []\n",
    "  #  for word in text:\n",
    "   #     if 'NN' in word[1]:\n",
    "    #        entity_list.append(word[0])\n",
    "    \n",
    "    lemmatized_list = []\n",
    "    for lit in text:\n",
    "        lmtz = wnl.lemmatize(lit)\n",
    "        lemmatized_list.append(lmtz)\n",
    "        lmt_string = ' '.join(lemmatized_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "a40b8ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "elist = []\n",
    "for word in sent_tokens:\n",
    "    elist.append(lemmatize_sentence(word,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2eed94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
